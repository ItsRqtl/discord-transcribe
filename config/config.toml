[bot]
debug-mode = false # logging level debug if true, else info
owners = []        # these users can bypass some limitations, can be empty

[transcriber]
model_size_or_path = "small" # Size of the model to use (tiny, tiny.en, base, base.en, small,
                             # small.en, medium, medium.en, large-v1, large-v2, large-v3, or
                             # large), a path to a converted model directory, or a
                             # CTranslate2-converted Whisper model ID from the HF Hub.
                             # When a size or a model ID is configured, the converted model is
                             # downloaded from the Hugging Face Hub.
device = "auto"       # Device to use for computation ("cpu", "cuda", "auto").
device_index = 0      # Device ID to use.
compute_type = "int8" # Type to use for computation.
                      # See https://opennmt.net/CTranslate2/quantization.html
cpu_threads = 4       # Number of threads to use when running on CPU only.


### Do not change the values below unless you know what you are doing. ###


[log]
format = "<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> | <level>{level: <8}</level> | <level>{message}</level>"

[database]
path = "storage/database.db"
